# æ¨¡å‹ç‰¹å¾å­ç©ºé—´åˆ†æå·¥å…· (Model Feature Subspace Analysis Tools)

æœ¬æ¨¡å—æä¾›äº†ä¸€å¥—å®Œæ•´çš„å·¥å…·ï¼Œç”¨äºå¯¹æ¯”åˆ†æå¤šä¸ªSNNæ¨¡å‹çš„ç‰¹å¾å­ç©ºé—´å·®å¼‚ã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
ESVAE/analysis/
â”œâ”€â”€ __init__.py                    # æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ README.md                      # æœ¬æ–‡æ¡£
â”œâ”€â”€ utils.py                       # å…±äº«å·¥å…·å‡½æ•°
â”œâ”€â”€ compare_parameters.py          # è„šæœ¬1: å‚æ•°å¯¹æ¯”
â”œâ”€â”€ extract_features_tsne.py       # è„šæœ¬2: ç‰¹å¾æå–ä¸t-SNEå¯è§†åŒ–
â””â”€â”€ compare_subspace_cka.py        # è„šæœ¬3: CKA/TCKAå­ç©ºé—´å¯¹æ¯”
```

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

### 1. `compare_parameters.py` - æ¨¡å‹å‚æ•°å¯¹æ¯”

**åŠŸèƒ½ï¼š**
- åŠ è½½ä¸¤ä¸ªæ¨¡å‹çš„checkpoint
- é€å±‚è®¡ç®—å‚æ•°å·®å¼‚ï¼ˆL2èŒƒæ•°ã€ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
- ç”Ÿæˆè¯¦ç»†çš„å¯¹æ¯”æŠ¥å‘Šï¼ˆCSVæ ¼å¼ï¼‰
- é‡ç‚¹åˆ†æå…³é”®å±‚ï¼ˆdvs_inputã€featuresã€bottleneckã€classifierï¼‰

**ä½¿ç”¨æ–¹æ³•ï¼š**

```bash
# ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
python -m ESVAE.analysis.compare_parameters \
    --baseline_ckpt /path/to/baseline_model.pth \
    --finetuned_ckpt /path/to/pretrained_finetuned_model.pth \
    --output_dir results/parameter_comparison
```

**è¾“å‡ºæ–‡ä»¶ï¼š**
- `parameter_comparison_full.csv` - å®Œæ•´çš„å‚æ•°å¯¹æ¯”ç»“æœ
- `parameter_comparison_dvs_input.csv` - DVSè¾“å…¥å±‚å‚æ•°å¯¹æ¯”
- `parameter_comparison_features.csv` - ç‰¹å¾å±‚å‚æ•°å¯¹æ¯”
- `parameter_comparison_bottleneck.csv` - Bottleneckå±‚å‚æ•°å¯¹æ¯”
- `parameter_comparison_classifier.csv` - åˆ†ç±»å™¨å±‚å‚æ•°å¯¹æ¯”

**å…³é”®æŒ‡æ ‡ï¼š**
- **L2 Difference**: å‚æ•°å‘é‡çš„L2èŒƒæ•°å·®å¼‚ï¼Œè¶Šå¤§è¡¨ç¤ºå‚æ•°å˜åŒ–è¶Šå¤§
- **Cosine Similarity**: å‚æ•°å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºæ–¹å‘è¶Šç›¸ä¼¼

---

### 2. `extract_features_tsne.py` - ç‰¹å¾æå–ä¸t-SNEå¯è§†åŒ–

**åŠŸèƒ½ï¼š**
- ä»ä¸¤ä¸ªæ¨¡å‹ä¸­æå–DVSç‰¹å¾
- ä½¿ç”¨t-SNEé™ç»´åˆ°2Dç©ºé—´
- ç”Ÿæˆå¤šç§å¯è§†åŒ–å¯¹æ¯”å›¾
- ç›´è§‚å±•ç¤ºç‰¹å¾ç©ºé—´çš„ç±»ç°‡ç»“æ„

**ä½¿ç”¨æ–¹æ³•ï¼š**

```bash
# ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
python -m ESVAE.analysis.extract_features_tsne \
    --baseline_ckpt /path/to/baseline_model.pth \
    --pretrained_ckpt /path/to/pretrained_model.pth \
    --data_path /path/to/n-caltech101 \
    --output_dir results/tsne_visualization \
    --max_samples 2000 \
    --layer_name bottleneck
```

**å‚æ•°è¯´æ˜ï¼š**
- `--max_samples`: ä½¿ç”¨çš„æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤2000ï¼‰
- `--layer_name`: è¦æå–ç‰¹å¾çš„å±‚åç§°ï¼ˆé»˜è®¤bottleneckï¼‰
- `--perplexity`: t-SNEçš„perplexityå‚æ•°ï¼ˆé»˜è®¤30ï¼‰
- `--learning_rate`: t-SNEçš„å­¦ä¹ ç‡ï¼ˆé»˜è®¤200ï¼‰

**è¾“å‡ºæ–‡ä»¶ï¼š**
- `tsne_baseline.png` - Baselineæ¨¡å‹çš„t-SNEå¯è§†åŒ–
- `tsne_pretrained.png` - é¢„è®­ç»ƒæ¨¡å‹çš„t-SNEå¯è§†åŒ–
- `tsne_comparison.png` - å¹¶æ’å¯¹æ¯”å›¾
- `tsne_overlay.png` - å åŠ æ˜¾ç¤ºå›¾ï¼ˆä½¿ç”¨ä¸åŒmarkerï¼‰

**å¯è§†åŒ–è¯´æ˜ï¼š**
- æ¯ä¸ªç‚¹ä»£è¡¨ä¸€ä¸ªæ ·æœ¬
- é¢œè‰²ä»£è¡¨ç±»åˆ«
- ç‚¹çš„èšé›†ç¨‹åº¦åæ˜ ç±»å†…ç´§å¯†åº¦
- ä¸åŒé¢œè‰²ç‚¹çš„åˆ†ç¦»ç¨‹åº¦åæ˜ ç±»é—´å¯åˆ†æ€§

---

### 3. `compare_subspace_cka.py` - CKA/TCKAå­ç©ºé—´å¯¹æ¯”

**åŠŸèƒ½ï¼š**
- æå–æ—¶åºç‰¹å¾ï¼ˆN, T, Dæ ¼å¼ï¼‰
- è®¡ç®—å¤šç§CKAæŒ‡æ ‡å®šé‡å¯¹æ¯”å­ç©ºé—´
- åˆ†æç¼–ç å±‚å’Œé«˜å±‚ç‰¹å¾çš„ç›¸ä¼¼åº¦
- ç”Ÿæˆè¯¦ç»†çš„æ•°å€¼æŠ¥å‘Š

**ä½¿ç”¨æ–¹æ³•ï¼š**

```bash
# ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
python -m ESVAE.analysis.compare_subspace_cka \
    --baseline_ckpt /path/to/baseline_model.pth \
    --pretrained_ckpt /path/to/pretrained_model.pth \
    --data_path /path/to/n-caltech101 \
    --output_dir results/cka_comparison \
    --max_samples 2000
```

**è¾“å‡ºæ–‡ä»¶ï¼š**
- `cka_comparison_results.txt` - è¯¦ç»†çš„CKAå¯¹æ¯”ç»“æœ

**CKAæŒ‡æ ‡è¯´æ˜ï¼š**

1. **Temporal Linear CKA (TCKA)**
   - å¯¹æ¯ä¸ªæ—¶é—´æ­¥åˆ†åˆ«è®¡ç®—CKAï¼Œç„¶åå–å¹³å‡
   - é€‚ç”¨äºSNNçš„æ—¶åºç‰¹å¾å¯¹æ¯”
   - å…¬å¼ï¼š`TCKA = (1/T) * Î£ CKA(f_t^A, f_t^B)`

2. **Linear CKA (SUM)**
   - å…ˆå¯¹æ—¶é—´ç»´åº¦æ±‚å’Œï¼Œå†è®¡ç®—CKA
   - å…³æ³¨æ•´ä½“æ—¶åºä¿¡æ¯çš„ç´¯ç§¯æ•ˆæœ

3. **Linear CKA (FLATTEN)**
   - å°†æ—¶é—´ç»´åº¦å±•å¹³åè®¡ç®—CKA
   - ä¿ç•™å®Œæ•´çš„æ—¶åºæ¨¡å¼ä¿¡æ¯

**CKAå€¼è§£é‡Šï¼š**
- CKA âˆˆ [0, 1]
- CKA = 1: ä¸¤ä¸ªç‰¹å¾å­ç©ºé—´å®Œå…¨ç›¸åŒ
- CKA = 0: ä¸¤ä¸ªç‰¹å¾å­ç©ºé—´å®Œå…¨ä¸ç›¸å…³
- CKA > 0.8: é«˜åº¦ç›¸ä¼¼
- 0.5 < CKA < 0.8: ä¸­ç­‰ç›¸ä¼¼
- CKA < 0.5: ç›¸ä¼¼åº¦è¾ƒä½

---

## ğŸ”§ å·¥å…·å‡½æ•° (`utils.py`)

### ä¸»è¦åŠŸèƒ½ï¼š

1. **`load_model_checkpoint()`**
   - åŠ è½½æ¨¡å‹checkpoint
   - è‡ªåŠ¨å¤„ç†DataParallelæ ¼å¼
   - æ”¯æŒå¤šç§checkpointæ ¼å¼

2. **`FeatureExtractor`**
   - ä½¿ç”¨hookæœºåˆ¶æå–ä¸­é—´å±‚ç‰¹å¾
   - æ”¯æŒå¤šå±‚åŒæ—¶æå–
   - è‡ªåŠ¨ç®¡ç†hookçš„æ³¨å†Œå’Œæ¸…ç†

3. **`extract_features_from_dataloader()`**
   - æ‰¹é‡æå–ç‰¹å¾
   - è‡ªåŠ¨å¤„ç†æ—¶åºç»´åº¦
   - æ”¯æŒè®¾ç½®æœ€å¤§æ ·æœ¬æ•°

4. **`get_layer_output_with_mem()`**
   - ä¸“é—¨ç”¨äºSNNçš„æ—¶åºç‰¹å¾æå–
   - ä¿ç•™å®Œæ•´çš„æ—¶é—´ç»´åº¦ä¿¡æ¯
   - å¯é€‰è¿”å›membrane potential

5. **`compute_parameter_difference()`**
   - è®¡ç®—ä¸¤ä¸ªæ¨¡å‹å‚æ•°çš„L2å·®å¼‚å’Œä½™å¼¦ç›¸ä¼¼åº¦
   - æ”¯æŒé€å±‚å¯¹æ¯”

6. **`print_layer_names()`**
   - æ‰“å°æ¨¡å‹æ‰€æœ‰å±‚çš„åç§°
   - ç”¨äºè°ƒè¯•å’Œç¡®å®šlayer_name

---

## ğŸ“Š å…¸å‹å·¥ä½œæµç¨‹

### åœºæ™¯ï¼šå¯¹æ¯”baselineå’Œé¢„è®­ç»ƒ+å¾®è°ƒæ¨¡å‹

```bash
# æ­¥éª¤1: å¯¹æ¯”æ¨¡å‹å‚æ•°
python -m ESVAE.analysis.compare_parameters \
    --baseline_ckpt checkpoints/baseline.pth \
    --finetuned_ckpt checkpoints/pretrained_finetuned.pth \
    --output_dir results/param_comparison

# æ­¥éª¤2: å¯è§†åŒ–ç‰¹å¾ç©ºé—´
python -m ESVAE.analysis.extract_features_tsne \
    --baseline_ckpt checkpoints/baseline.pth \
    --pretrained_ckpt checkpoints/pretrained_finetuned.pth \
    --data_path /path/to/n-caltech101 \
    --output_dir results/tsne_vis \
    --max_samples 2000

# æ­¥éª¤3: å®šé‡å¯¹æ¯”å­ç©ºé—´
python -m ESVAE.analysis.compare_subspace_cka \
    --baseline_ckpt checkpoints/baseline.pth \
    --pretrained_ckpt checkpoints/pretrained_finetuned.pth \
    --data_path /path/to/n-caltech101 \
    --output_dir results/cka_comparison \
    --max_samples 2000
```

---

## ğŸ” å¦‚ä½•é€‰æ‹©layer_name

è¦æŸ¥çœ‹æ¨¡å‹ä¸­æ‰€æœ‰å¯ç”¨çš„å±‚åç§°ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š

```python
from ESVAE.models.snn_models.VGG import VGGSNN
from ESVAE.analysis.utils import print_layer_names

model = VGGSNN(in_channel=2, cls_num=101, img_shape=48)
print_layer_names(model)
```

**å¸¸ç”¨å±‚åç§°ï¼š**
- `dvs_input` - DVSè¾“å…¥å±‚ï¼ˆç¼–ç å±‚ï¼‰
- `features` - ç‰¹å¾æå–å±‚ï¼ˆæ•´ä¸ªSequentialï¼‰
- `features.0` - ç¬¬ä¸€ä¸ªç‰¹å¾å±‚
- `features.1` - ç¬¬äºŒä¸ªç‰¹å¾å±‚ï¼ˆæ± åŒ–åï¼‰
- `bottleneck` - ç“¶é¢ˆå±‚ï¼ˆé«˜å±‚ç‰¹å¾ï¼‰
- `classifier` - åˆ†ç±»å™¨

---

## ğŸ“ ä»£ç ç¤ºä¾‹

### ç¤ºä¾‹1: åœ¨Pythonè„šæœ¬ä¸­ä½¿ç”¨

```python
from ESVAE.analysis.compare_parameters import compare_model_parameters

# å¯¹æ¯”å‚æ•°
results = compare_model_parameters(
    baseline_ckpt_path="checkpoints/baseline.pth",
    finetuned_ckpt_path="checkpoints/finetuned.pth",
    output_dir="results/comparison",
    device="cuda"
)

# æŸ¥çœ‹ç»“æœ
print(results.head())
```

### ç¤ºä¾‹2: è‡ªå®šä¹‰ç‰¹å¾æå–

```python
import torch
from ESVAE.models.snn_models.VGG import VGGSNN
from ESVAE.analysis.utils import FeatureExtractor

# åˆ›å»ºæ¨¡å‹
model = VGGSNN(in_channel=2, cls_num=101, img_shape=48)
model.load_state_dict(torch.load("model.pth"))
model.eval()

# åˆ›å»ºç‰¹å¾æå–å™¨
extractor = FeatureExtractor(model, ['dvs_input', 'bottleneck'])

# æå–ç‰¹å¾
features_dict = extractor.extract(input_data)

# è®¿é—®ç‰¹å¾
dvs_features = features_dict['dvs_input']
bottleneck_features = features_dict['bottleneck']

# æ¸…ç†
extractor.remove_hooks()
```

---

## âš™ï¸ ç¯å¢ƒè¦æ±‚

```bash
# å¿…éœ€çš„PythonåŒ…
torch>=1.8.0
numpy>=1.19.0
pandas>=1.2.0
matplotlib>=3.3.0
scikit-learn>=0.24.0
tqdm>=4.60.0
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ‰¾ä¸åˆ°layer_name
**A:** ä½¿ç”¨`print_layer_names()`æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å±‚åç§°ï¼Œç¡®ä¿æ‹¼å†™æ­£ç¡®ã€‚

### Q2: CUDA out of memory
**A:** å‡å°`--batch_size`æˆ–`--max_samples`å‚æ•°ã€‚

### Q3: t-SNEè¿è¡Œæ—¶é—´è¿‡é•¿
**A:** å‡å°`--max_samples`ï¼ˆæ¨è1000-2000ï¼‰ï¼Œæˆ–è°ƒæ•´`--perplexity`å‚æ•°ã€‚

### Q4: CKAå€¼ä¸ºNaN
**A:** æ£€æŸ¥ç‰¹å¾æ˜¯å¦åŒ…å«NaNæˆ–Infï¼Œå¯èƒ½éœ€è¦åœ¨æ¨¡å‹è®­ç»ƒæ—¶æ·»åŠ æ¢¯åº¦è£å‰ªã€‚

### Q5: ç‰¹å¾ç»´åº¦ä¸åŒ¹é…
**A:** ç¡®ä¿ä¸¤ä¸ªæ¨¡å‹ä½¿ç”¨ç›¸åŒçš„æ¶æ„å’Œè¾“å…¥å°ºå¯¸ã€‚

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **CKA (Centered Kernel Alignment)**
   - Kornblith et al. "Similarity of Neural Network Representations Revisited." ICML 2019.

2. **t-SNE**
   - van der Maaten & Hinton. "Visualizing Data using t-SNE." JMLR 2008.

3. **Temporal Efficient Training**
   - Deng et al. "Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting." ICLR 2022.

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚

---

## ğŸ“„ è®¸å¯è¯

æœ¬æ¨¡å—éµå¾ªé¡¹ç›®ä¸»è®¸å¯è¯ã€‚

